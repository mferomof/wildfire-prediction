{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from load_dataset import WildfireDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19 = [64,64,'M',128,128,'M',256,256,256,256,'M',512,512,512,\n",
    "         512,'M',512,512,512,512,'M']\n",
    "#Then flatten and 4096*4096*1000 Lineal Layers\n",
    "\n",
    "class VGG_net(nn.Module):\n",
    "    #in channels=3 because images should be RGB, we put \n",
    "    #1000 classes by default \n",
    "    def __init__(self, in_channels=3, num_classes=1000):\n",
    "        super(VGG_net,self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_layers = self.create_conv_layers(VGG19) #the function\n",
    "        #created below, with the parameters from the list VGG16\n",
    "        \n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 4096), # the 7 is obtained from dividing\n",
    "            #224 (the fixed size of the image) by 2**5 where 5 is \n",
    "            #the number of max pooling layers applied and contained\n",
    "            #in the VGG16 list, the 4096 is gotten from the paper\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5), \n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5), \n",
    "            nn.Linear(4096,num_classes)\n",
    "            \n",
    "            ) \n",
    "        #fully connected layers \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0],-1) #to flatten it for the linear part \n",
    "        x = self.fcs(x) #the flattened part is sent to the fully connected layers \n",
    "        return x\n",
    "    \n",
    "    def create_conv_layers(self,architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "        \n",
    "        for x in architecture:\n",
    "            if type(x) == int: #in the VGG16 list the integers\n",
    "            #represent a convolutional layer\n",
    "                out_channels = x\n",
    "                \n",
    "                layers += [nn.Conv2d(in_channels=in_channels, \n",
    "                                     out_channels=out_channels,\n",
    "                                     kernel_size=(3,3),\n",
    "                                     stride=(1,1),\n",
    "                                     padding=(1,1)),\n",
    "                                     nn.BatchNorm2d(x), #this was not originally in the paper, but\n",
    "                                     #it is supposed to improve the performance\n",
    "                                     nn.ReLU()]\n",
    "                \n",
    "                in_channels = x #the new input channels are the outÂ´put channels from the previous layer\n",
    "            elif x=='M': #if the element in the list is an M, we have a max pooling layer\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))]\n",
    "                \n",
    "        return nn.Sequential(*layers) #unpacking all that was stored in the empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"train/\"\n",
    "path_validation = \"valid/\"\n",
    "path_test = \"test/\"\n",
    "\n",
    "folder1 = \"nowildfire\"\n",
    "folder2 = \"wildfire\"\n",
    "\n",
    "folders = [folder1, folder2]\n",
    "path_t = [path_train,path_validation,path_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get file path+file_names to use in the dataloader\n",
    "\n",
    "num_files = []\n",
    "name_files = []\n",
    "\n",
    "for path in path_t:\n",
    "    file_name_class = []\n",
    "    num_files_class = []\n",
    "    for folder in folders:\n",
    "        list_files = os.listdir(path+folder)\n",
    "        list_files = [path+folder+\"/\" + x for x in list_files]\n",
    "        num = len(list_files)\n",
    "        file_name_class = file_name_class + list_files\n",
    "        num_files_class.append(num)\n",
    "    name_files.append(file_name_class)\n",
    "    num_files.append(num_files_class)\n",
    "\n",
    "label_train = [0]*num_files[0][0] + [1]*num_files[0][1]\n",
    "label_val = [0]*num_files[1][0] + [1]*num_files[1][1]\n",
    "label_test = [0]*num_files[2][0] + [1]*num_files[2][1]\n",
    "\n",
    "temp_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(), #we first do this since the transformations are usually applied to this format\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean and std for normalization \n",
    "\n",
    "# Create a DataLoader for the training data\n",
    "train_dataset = WildfireDataset(name_files[0], label_train, transform=temp_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Calculate mean and std\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "total_images = 0\n",
    "\n",
    "print(\"Calculating mean and standard deviation...\")\n",
    "for images, _ in train_loader:\n",
    "    # Reshape the images to (batch_size, num_channels, -1)\n",
    "    images = images.view(images.size(0), images.size(1), -1)\n",
    "    \n",
    "    # Calculate mean and std per channel\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    \n",
    "    total_images += images.size(0)\n",
    "\n",
    "# Final calculation\n",
    "mean /= total_images\n",
    "std /= total_images\n",
    "\n",
    "print(f\"Calculated Mean: {mean.tolist()}\")\n",
    "print(f\"Calculated Standard Deviation: {std.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrate normalization to transforms\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean.tolist(), std=std.tolist())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WildfireDataset(name_files[0],label_train,transform = my_transforms)\n",
    "train_loader=DataLoader(train_dataset, batch_size=64, num_workers=1, shuffle=True)\n",
    "\n",
    "val_dataset = WildfireDataset(name_files[1],label_val,transform = my_transforms)\n",
    "val_loader=DataLoader(val_dataset, batch_size=64, num_workers=1, shuffle=True)\n",
    "\n",
    "test_dataset = WildfireDataset(name_files[2],label_test,transform = my_transforms)\n",
    "test_loader=DataLoader(test_dataset, batch_size=64, num_workers=1, shuffle=True)\n",
    "\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = VGG_net(in_channels=3,num_classes=2).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(),lr=0.01)\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "ep_loss_train = []\n",
    "ep_acc_train = []\n",
    "\n",
    "ep_loss_val = []\n",
    "ep_acc_val = []\n",
    "\n",
    "for k in range(epochs):\n",
    "    print(\"Starting...\")\n",
    "    # TRAIN\n",
    "    train_losses = []\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "\n",
    "    network.train()\n",
    "\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for img, label in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {k}\")\n",
    "\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # Clear the gradients\n",
    "            \n",
    "            target = network(img) # Forward Pass\n",
    "\n",
    "            loss = criterion(target,label) # Find the Loss\n",
    "            loss.backward() # Calculate gradients \n",
    "\n",
    "            optimizer.step() # Update Weights\n",
    "\n",
    "            train_loss += loss.item() # Calculate Loss\n",
    "            train_losses.append(loss.item()) #To keep track of the loss\n",
    "\n",
    "            pred = target.argmax(1, keepdim=True) # get the index of the max log-probability, argmax already computes softmax\n",
    "            correct_train += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "            #tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy)\n",
    "\n",
    "    # VALIDATION\n",
    "    valid_losses = []\n",
    "    valid_loss = 0.0 # Reset to 0 for each epoch\n",
    "    correct_val = 0\n",
    "\n",
    "    network.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            img, label = batch\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            target = network(img)\n",
    "\n",
    "            loss = criterion(target,label)\n",
    "\n",
    "            valid_loss += loss.item() * img.size(0)\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "            pred = target.argmax(1, keepdim=True) # get the index of the max log-probability, argmax already computes softmax\n",
    "            correct_val += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "    #Calculate the average epoch loss and accuracy\n",
    "    ep_loss_train.append(train_loss / len(train_loader.dataset))\n",
    "    ep_acc_train.append(100. * correct_train / len(train_loader.dataset))\n",
    "\n",
    "    ep_loss_val.append(valid_loss / len(val_loader.dataset))\n",
    "    ep_acc_val.append(100. * correct_val / len(val_loader.dataset))\n",
    "\n",
    "    print(f'Epoch {k+1} \\t\\t Training Loss: {train_loss / len(train_loader.dataset)} \\t\\t Validation Loss: {valid_loss / len(val_loader.dataset)}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(network.state_dict(), 'saved_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(ep_loss_train, label=\"Training Loss\")\n",
    "plt.plot(ep_loss_val, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.plot(ep_acc_train, label=\"Training Accuracy\")\n",
    "plt.plot(ep_acc_val, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "network.load_state_dict(torch.load('saved_model.pth')) #Load the params of the best saved model\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "network.eval() # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad(): # Don't calculate gradients, only forward pass\n",
    "    for img, label in test_loader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        target = network(img)\n",
    "        loss = criterion(target, label)\n",
    "        test_loss += loss.item() * img.size(0)\n",
    "\n",
    "        pred = target.argmax(1) # get the index of the max log-probability\n",
    "        correct_test += pred.eq(label).sum().item()\n",
    "        \n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "# Calculate final test accuracy and loss\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_accuracy = 100. * correct_test / len(test_loader.dataset)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "class_names = [\"No Wildfire\", \"Wildfire\"]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
